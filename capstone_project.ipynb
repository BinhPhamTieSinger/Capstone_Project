{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXeBxl6apymQ"
      },
      "source": [
        "# Capstone Project: AI Agent with PDF Knowledge Integration\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "Congratulations on reaching the capstone project! In this project, you will build a complete **AI Agent Chatbot** that can:\n",
        "\n",
        "1. **Learn from PDF documents** - Upload and process PDF files to expand the knowledge base\n",
        "2. **Use tools intelligently** - Calculator, date/time, and knowledge search tools\n",
        "3. **Maintain conversation memory** - Remember context across multiple turns\n",
        "4. **Provide a user-friendly interface** - Using Streamlit\n",
        "\n",
        "This project integrates everything you've learned in the LangChain tutorials!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etRLMQErpymY"
      },
      "source": [
        "---\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By completing this project, you will demonstrate proficiency in:\n",
        "\n",
        "| Skill | Description |\n",
        "|-------|-------------|\n",
        "| **LCEL** | Modern chain composition with `prompt \\| llm \\| parser` |\n",
        "| **Tool Creation** | Defining tools with `@tool` decorator |\n",
        "| **LangGraph** | Building agents with `StateGraph` and explicit nodes |\n",
        "| **RAG Pipeline** | Embeddings, vector stores, retrieval |\n",
        "| **PDF Processing** | Document loading and text extraction |\n",
        "| **Streamlit** | Building interactive web applications |\n",
        "| **State Management** | Handling conversation history and session state |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX1NPniSpymZ"
      },
      "source": [
        "---\n",
        "\n",
        "## Architecture\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                         AI AGENT CHATBOT ARCHITECTURE                        â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                                             â”‚\n",
        "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
        "â”‚   â”‚                        STREAMLIT INTERFACE                           â”‚  â”‚\n",
        "â”‚   â”‚                                                                      â”‚  â”‚\n",
        "â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚\n",
        "â”‚   â”‚   â”‚  PDF Upload  â”‚   â”‚  Chat Input  â”‚   â”‚   Conversation View  â”‚   â”‚  â”‚\n",
        "â”‚   â”‚   â”‚   Widget     â”‚   â”‚   Widget     â”‚   â”‚   (History Display)  â”‚   â”‚  â”‚\n",
        "â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚\n",
        "â”‚   â”‚                                                                      â”‚  â”‚\n",
        "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
        "â”‚                                    â”‚                                        â”‚\n",
        "â”‚                                    â–¼                                        â”‚\n",
        "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
        "â”‚   â”‚                    LANGGRAPH AGENT (StateGraph)                      â”‚  â”‚\n",
        "â”‚   â”‚                                                                      â”‚  â”‚\n",
        "â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚\n",
        "â”‚   â”‚   â”‚                  Agent Node (GPT-5-mini)                      â”‚  â”‚  â”‚\n",
        "â”‚   â”‚   â”‚                                                              â”‚  â”‚  â”‚\n",
        "â”‚   â”‚   â”‚   Decides which tools to use based on user input             â”‚  â”‚  â”‚\n",
        "â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚\n",
        "â”‚   â”‚                              â”‚                                       â”‚  â”‚\n",
        "â”‚   â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚  â”‚\n",
        "â”‚   â”‚              â”‚                               â”‚                      â”‚  â”‚\n",
        "â”‚   â”‚              â–¼                               â–¼                      â”‚  â”‚\n",
        "â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚\n",
        "â”‚   â”‚   â”‚  Your Custom Tool    â”‚       â”‚  Knowledge Search    â”‚          â”‚  â”‚\n",
        "â”‚   â”‚   â”‚  (You design this!)  â”‚       â”‚  (search_documents)  â”‚          â”‚  â”‚\n",
        "â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚\n",
        "â”‚   â”‚                                               â”‚                     â”‚  â”‚\n",
        "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
        "â”‚                                                   â”‚                        â”‚\n",
        "â”‚                                                   â–¼                        â”‚\n",
        "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
        "â”‚   â”‚                     RAG PIPELINE                                     â”‚  â”‚\n",
        "â”‚   â”‚                                                                      â”‚  â”‚\n",
        "â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚\n",
        "â”‚   â”‚   â”‚  PDF Loader  â”‚â”€â”€>â”‚  Embeddings  â”‚â”€â”€>â”‚  Pinecone Vector DB  â”‚   â”‚  â”‚\n",
        "â”‚   â”‚   â”‚  (PyPDF)     â”‚   â”‚  (OpenAI)    â”‚   â”‚  (Similarity Search) â”‚   â”‚  â”‚\n",
        "â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚\n",
        "â”‚   â”‚                                                                      â”‚  â”‚\n",
        "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
        "â”‚                                                                             â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "LangGraph Workflow:\n",
        "  START â”€â”€> agent_node â”€â”€> should_continue? â”€â”€â”¬â”€â”€> tools_node â”€â”€> agent_node\n",
        "                                              â””â”€â”€> END\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITt1CXCTpyma"
      },
      "source": [
        "---\n",
        "\n",
        "## Requirements\n",
        "\n",
        "### Minimum Requirements (Required for Passing)\n",
        "\n",
        "Your project MUST include:\n",
        "\n",
        "| Requirement | Description | Points |\n",
        "|------------|-------------|--------|\n",
        "| **PDF Upload** | Users can upload PDF files through the interface | 15 |\n",
        "| **PDF Processing** | Extract text from PDFs and add to vector store | 15 |\n",
        "| **Vector Store** | Use Pinecone to store document embeddings | 10 |\n",
        "| **search_documents Tool** | Tool that retrieves relevant document chunks | 15 |\n",
        "| **Custom Tool** | Create your OWN tool (be creative!) | 15 |\n",
        "| **LangGraph Agent** | Build agent with StateGraph pattern | 15 |\n",
        "| **Chat Interface** | Streamlit-based chat with history display | 10 |\n",
        "| **Code Quality** | Clean, well-commented code | 5 |\n",
        "| **TOTAL** | | **100** |\n",
        "\n",
        "### Bonus Features (Extra Credit)\n",
        "\n",
        "| Feature | Description | Bonus Points |\n",
        "|---------|-------------|-------------|\n",
        "| **Voice Input** | Add microphone input for hands-free chatting | +10 |\n",
        "| **Multiple File Types** | Support for TXT, DOCX, or other formats | +10 |\n",
        "| **Additional Tools** | Create more custom tools | +5 each |\n",
        "| **Advanced LangGraph** | Add conditional routing or parallel nodes | +15 |\n",
        "| **Deployment** | Deploy to Streamlit Cloud or similar | +10 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZa262qQpymb"
      },
      "source": [
        "---\n",
        "\n",
        "## Implementation Guide\n",
        "\n",
        "### Step 1: Setup and Dependencies\n",
        "\n",
        "Create a `.env` file with your API keys:\n",
        "\n",
        "```\n",
        "OPENAI_API_KEY=your-openai-key-here\n",
        "PINECONE_API_KEY=your-pinecone-key-here\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX0cFbBcpymc"
      },
      "outputs": [],
      "source": [
        "# Required imports - Add these to your Streamlit app\n",
        "\n",
        "import os\n",
        "from typing import TypedDict, Annotated\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.tools import tool\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "# LangGraph imports (for building agents)\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# PDF processing\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Pinecone\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Streamlit\n",
        "import streamlit as st\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwtIPMZdpymd"
      },
      "source": [
        "### Step 2: Create Your Tools\n",
        "\n",
        "Tools give your chatbot special abilities! The LLM reads the tool's **docstring** to decide when to use it.\n",
        "\n",
        "#### Required Tool\n",
        "- **`search_documents`**: Searches the PDF knowledge base (this is required for the RAG feature)\n",
        "\n",
        "#### Your Custom Tool\n",
        "Create at least **ONE custom tool** of your choice. Be creative!\n",
        "\n",
        "**Tool Ideas:**\n",
        "| Tool | What It Does | Difficulty |\n",
        "|------|--------------|------------|\n",
        "| Word Counter | Counts words in text | Easy |\n",
        "| Calculator | Does math calculations | Easy |\n",
        "| Text Summarizer | Summarizes long text | Medium |\n",
        "| Sentiment Analyzer | Detects positive/negative tone | Medium |\n",
        "| URL Fetcher | Gets webpage content | Medium |\n",
        "| Translator | Translates text to another language | Medium |\n",
        "\n",
        "**Important**: The **docstring is crucial**! Write clear descriptions so the LLM knows WHEN to use your tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xL_G5v1pyme"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# TOOL CREATION GUIDE\n",
        "# ============================================================\n",
        "#\n",
        "# Every tool needs 3 things:\n",
        "#   1. @tool decorator\n",
        "#   2. Clear docstring (LLM reads this to decide when to use it!)\n",
        "#   3. Function body that returns a string\n",
        "#\n",
        "# TEMPLATE:\n",
        "#\n",
        "#   @tool\n",
        "#   def my_tool_name(parameter: str) -> str:\n",
        "#       \"\"\"Short description of what this tool does.\n",
        "#\n",
        "#       Use this tool when:\n",
        "#       - [Situation 1 when LLM should use this tool]\n",
        "#       - [Situation 2]\n",
        "#\n",
        "#       Args:\n",
        "#           parameter: Description of the parameter\n",
        "#\n",
        "#       Returns:\n",
        "#           Description of what is returned\n",
        "#       \"\"\"\n",
        "#       # Your implementation here\n",
        "#       result = do_something(parameter)\n",
        "#       return str(result)\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "# REQUIRED TOOL: Document Search (for RAG)\n",
        "# You MUST implement this tool for the PDF knowledge base feature\n",
        "\n",
        "@tool\n",
        "def search_documents(query: str) -> str:\n",
        "    \"\"\"Search uploaded PDF documents for relevant information.\n",
        "\n",
        "    Use this tool when:\n",
        "    - User asks about content from uploaded documents\n",
        "    - User mentions 'the PDF', 'the document', or 'the file'\n",
        "    - User asks questions that might be answered by document content\n",
        "\n",
        "    Args:\n",
        "        query: The search query to find relevant passages\n",
        "\n",
        "    Returns:\n",
        "        Relevant text passages from the documents, or a message if nothing found\n",
        "    \"\"\"\n",
        "    # TODO: Implement this!\n",
        "    #\n",
        "    # Hint: Use something like this:\n",
        "    #   docs = st.session_state.vector_store.similarity_search(query, k=3)\n",
        "    #   if not docs:\n",
        "    #       return \"No relevant information found in the documents.\"\n",
        "    #   results = []\n",
        "    #   for i, doc in enumerate(docs, 1):\n",
        "    #       results.append(f\"[Passage {i}]: {doc.page_content[:500]}\")\n",
        "    #   return \"\\n\\n\".join(results)\n",
        "    pass\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# YOUR CUSTOM TOOL - Be creative!\n",
        "# ============================================================\n",
        "#\n",
        "# Pick an idea from the table above, or invent your own!\n",
        "# Remember: The docstring tells the LLM WHEN to use your tool.\n",
        "\n",
        "@tool\n",
        "def your_custom_tool(input_text: str) -> str:\n",
        "    \"\"\"[YOUR DESCRIPTION HERE - What does this tool do?]\n",
        "\n",
        "    Use this tool when:\n",
        "    - [WHEN SHOULD THE LLM USE THIS?]\n",
        "    - [ADD MORE CONDITIONS IF NEEDED]\n",
        "\n",
        "    Args:\n",
        "        input_text: [WHAT DOES THIS PARAMETER REPRESENT?]\n",
        "\n",
        "    Returns:\n",
        "        [WHAT DOES THIS TOOL RETURN?]\n",
        "    \"\"\"\n",
        "    # TODO: Implement your creative tool here!\n",
        "    #\n",
        "    # Example ideas:\n",
        "    # - Word counter: return f\"The text has {len(input_text.split())} words.\"\n",
        "    # - Calculator: return str(eval(input_text))  # Be careful with eval!\n",
        "    # - Uppercase: return input_text.upper()\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t88YSuBHpymf"
      },
      "source": [
        "### Step 3: PDF Processing Function\n",
        "\n",
        "Create a function to process uploaded PDF files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQijPNjCpymf"
      },
      "outputs": [],
      "source": [
        "def process_pdf(uploaded_file):\n",
        "    \"\"\"\n",
        "    Process an uploaded PDF file and add to vector store.\n",
        "\n",
        "    Steps:\n",
        "    1. Save the uploaded file temporarily\n",
        "    2. Load the PDF using PyPDFLoader\n",
        "    3. Split into chunks using RecursiveCharacterTextSplitter\n",
        "    4. Add to Pinecone vector store\n",
        "\n",
        "    Args:\n",
        "        uploaded_file: Streamlit UploadedFile object\n",
        "\n",
        "    Returns:\n",
        "        str: Success or error message\n",
        "    \"\"\"\n",
        "    # TODO: Implement PDF processing\n",
        "\n",
        "    # Step 1: Save uploaded file temporarily\n",
        "    # temp_path = f\"/tmp/{uploaded_file.name}\"\n",
        "    # with open(temp_path, \"wb\") as f:\n",
        "    #     f.write(uploaded_file.getbuffer())\n",
        "\n",
        "    # Step 2: Load with PyPDFLoader (from langchain_community.document_loaders)\n",
        "    # loader = PyPDFLoader(temp_path)\n",
        "    # documents = loader.load()\n",
        "\n",
        "    # Step 3: Split into chunks (from langchain_text_splitters)\n",
        "    # text_splitter = RecursiveCharacterTextSplitter(\n",
        "    #     chunk_size=1024,\n",
        "    #     chunk_overlap=256\n",
        "    # )\n",
        "    # chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Step 4: Add to vector store\n",
        "    # st.session_state.vector_store.add_documents(chunks)\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB__0-Expymg"
      },
      "source": [
        "### Step 4: Create the Agent with LangGraph\n",
        "\n",
        "Build the agent using LangGraph's `StateGraph` for explicit control over the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUzd03Szpymg"
      },
      "outputs": [],
      "source": [
        "# Define the state schema for your agent\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"State that flows through the agent graph.\"\"\"\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "def create_agent_graph():\n",
        "    \"\"\"\n",
        "    Create the agent using LangGraph StateGraph.\n",
        "\n",
        "    Architecture:\n",
        "    START -> agent_node -> should_continue? -> tools_node -> agent_node -> ...\n",
        "                                            -> END\n",
        "\n",
        "    Returns:\n",
        "        Compiled LangGraph agent with memory\n",
        "    \"\"\"\n",
        "    # Define your tools - add your custom tool here!\n",
        "    tools = [search_documents, your_custom_tool]\n",
        "\n",
        "    # Create the LLM with tool binding\n",
        "    llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
        "    llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "    # Define the agent node\n",
        "    def agent_node(state: AgentState) -> dict:\n",
        "        \"\"\"The main agent that decides what to do.\"\"\"\n",
        "        system_prompt = \"\"\"You are a helpful AI assistant with access to tools.\n",
        "\n",
        "        You have tools available to help answer questions. Use them when appropriate:\n",
        "        - search_documents: For finding information in uploaded PDFs\n",
        "        - [Your custom tool]: [Describe when to use it]\n",
        "\n",
        "        Always try to be helpful and use tools when they can provide better answers.\"\"\"\n",
        "\n",
        "        messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
        "        response = llm_with_tools.invoke(messages)\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "    # Define the conditional edge function\n",
        "    def should_continue(state: AgentState) -> str:\n",
        "        \"\"\"Decide whether to use tools or end the conversation.\"\"\"\n",
        "        last_message = state[\"messages\"][-1]\n",
        "        if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "            return \"tools\"\n",
        "        return \"end\"\n",
        "\n",
        "    # Build the graph\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"agent\", agent_node)\n",
        "    workflow.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "    # Add edges\n",
        "    workflow.add_edge(START, \"agent\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"agent\",\n",
        "        should_continue,\n",
        "        {\"tools\": \"tools\", \"end\": END}\n",
        "    )\n",
        "    workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "    # Compile with memory for conversation persistence\n",
        "    memory = MemorySaver()\n",
        "    agent = workflow.compile(checkpointer=memory)\n",
        "\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz5AENH6pymh"
      },
      "source": [
        "### Step 5: Streamlit App Structure\n",
        "\n",
        "Here's the skeleton for your Streamlit app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyoTwVdOpymh"
      },
      "outputs": [],
      "source": [
        "# Streamlit App Skeleton - Save this as 'app.py'\n",
        "\n",
        "\"\"\"\n",
        "def main():\n",
        "    # Page config\n",
        "    st.set_page_config(page_title=\"PDF Agent Chatbot\", page_icon=\"ðŸ“„\")\n",
        "    st.title(\"ðŸ“„ PDF Knowledge Agent\")\n",
        "\n",
        "    # Initialize session state\n",
        "    if \"initialized\" not in st.session_state:\n",
        "        # TODO: Initialize vector store\n",
        "        # TODO: Initialize LangGraph agent\n",
        "        # TODO: Initialize message history\n",
        "        st.session_state.agent = create_agent_graph()\n",
        "        st.session_state.message_history = []\n",
        "        st.session_state.thread_id = \"user-session-1\"\n",
        "        st.session_state.initialized = True\n",
        "\n",
        "    # Sidebar for PDF upload\n",
        "    with st.sidebar:\n",
        "        st.header(\"ðŸ“¤ Upload PDF\")\n",
        "        uploaded_file = st.file_uploader(\"Choose a PDF\", type=\"pdf\")\n",
        "\n",
        "        if uploaded_file and st.button(\"Process PDF\"):\n",
        "            with st.spinner(\"Processing...\"):\n",
        "                # TODO: Call process_pdf function\n",
        "                pass\n",
        "\n",
        "    # Display chat history\n",
        "    for message in st.session_state.message_history:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # Chat input\n",
        "    if user_input := st.chat_input(\"Ask a question...\"):\n",
        "        # Display user message\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(user_input)\n",
        "\n",
        "        # Add to history\n",
        "        st.session_state.message_history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_input\n",
        "        })\n",
        "\n",
        "        # Generate response using LangGraph agent\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            with st.spinner(\"Thinking...\"):\n",
        "                # Invoke the LangGraph agent\n",
        "                config = {\"configurable\": {\"thread_id\": st.session_state.thread_id}}\n",
        "                result = st.session_state.agent.invoke(\n",
        "                    {\"messages\": [HumanMessage(content=user_input)]},\n",
        "                    config=config\n",
        "                )\n",
        "\n",
        "                # Get the last AI message\n",
        "                response = result[\"messages\"][-1].content\n",
        "                st.markdown(response)\n",
        "\n",
        "                # Add to history\n",
        "                st.session_state.message_history.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": response\n",
        "                })\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\"\n",
        "\n",
        "print(\"App skeleton ready! Copy this to your app.py file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qIl49Wnpymh"
      },
      "source": [
        "---\n",
        "\n",
        "## Testing Your Implementation\n",
        "\n",
        "Use these test cases to verify your implementation works correctly:\n",
        "\n",
        "### Test Case 1: Basic Chat\n",
        "- **Input**: \"Hello, how are you?\"\n",
        "- **Expected**: Friendly response without tool use\n",
        "\n",
        "### Test Case 2: PDF Upload\n",
        "1. Upload a sample PDF\n",
        "2. Verify success message\n",
        "3. Check vector store has embeddings\n",
        "\n",
        "### Test Case 3: Document Search Tool\n",
        "- **Input**: \"What does the document say about [topic]?\"\n",
        "- **Expected**: Uses `search_documents` tool, returns relevant content from PDF\n",
        "\n",
        "### Test Case 4: Your Custom Tool\n",
        "- **Input**: [A query that should trigger YOUR custom tool]\n",
        "- **Expected**: Uses your custom tool and returns appropriate result\n",
        "\n",
        "### Test Case 5: Conversation Memory\n",
        "1. Say: \"My name is Alice\"\n",
        "2. Say: \"What is my name?\"\n",
        "- **Expected**: Correctly remembers and returns \"Alice\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yn0WcL2pymi"
      },
      "source": [
        "---\n",
        "\n",
        "## Submission Guidelines\n",
        "\n",
        "### What to Submit\n",
        "\n",
        "1. **Source Code** (Required)\n",
        "   - Your complete Streamlit app (`app.py` or similar)\n",
        "   - Any helper modules you created\n",
        "   - `.env.example` file (WITHOUT actual API keys!)\n",
        "   - `requirements.txt` with dependencies\n",
        "\n",
        "2. **Video Demo** (Required)\n",
        "   - Record a 3-5 minute video demonstrating:\n",
        "     - PDF upload and processing\n",
        "     - Asking questions about the PDF content\n",
        "     - Using the calculator tool\n",
        "     - Multi-turn conversation with memory\n",
        "   - Upload to the shared folder: `luanpham.datascience@gmail.com`\n",
        "\n",
        "3. **README** (Recommended)\n",
        "   - Brief description of your implementation\n",
        "   - Any bonus features you added\n",
        "   - Known limitations or issues\n",
        "\n",
        "### Evaluation Rubric\n",
        "\n",
        "| Criteria | Excellent (90-100%) | Good (70-89%) | Needs Work (<70%) |\n",
        "|----------|---------------------|---------------|-------------------|\n",
        "| **Functionality** | All features work perfectly | Most features work | Major bugs |\n",
        "| **Code Quality** | Clean, well-documented | Readable but minimal docs | Hard to understand |\n",
        "| **Tool Integration** | Tools work seamlessly | Tools work but with issues | Tools don't work |\n",
        "| **UI/UX** | Polished, intuitive | Functional but basic | Confusing or broken |\n",
        "| **Demo Video** | Clear, shows all features | Shows most features | Missing key demos |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucMnYFqPpymi"
      },
      "source": [
        "---\n",
        "\n",
        "## Helpful Resources\n",
        "\n",
        "### Documentation\n",
        "- [LangChain Documentation](https://python.langchain.com/)\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
        "- [Pinecone Documentation](https://docs.pinecone.io/)\n",
        "- [Streamlit Documentation](https://docs.streamlit.io/)\n",
        "\n",
        "### Sample PDFs for Testing\n",
        "You can use any PDF for testing, but here are some suggestions:\n",
        "- Company reports or documentation\n",
        "- Academic papers\n",
        "- Technical documentation\n",
        "- Any text-heavy PDF\n",
        "\n",
        "### Troubleshooting Tips\n",
        "\n",
        "| Issue | Solution |\n",
        "|-------|----------|\n",
        "| API key not found | Check `.env` file and `load_dotenv()` call |\n",
        "| Pinecone index error | Verify index exists and dimensions match |\n",
        "| PDF not loading | Check file path and PyPDFLoader import |\n",
        "| Agent not using tools | Check tool docstrings are descriptive |\n",
        "| Memory not working | Verify `checkpointer` is passed to `compile()` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMzkkhUWpymi"
      },
      "source": [
        "---\n",
        "\n",
        "## Good Luck!\n",
        "\n",
        "This capstone project is your opportunity to showcase everything you've learned. Take your time, test thoroughly, and don't hesitate to revisit the tutorial notebooks if you need a refresher on any concept.\n",
        "\n",
        "Remember:\n",
        "- Start with the basic requirements first\n",
        "- Test each component individually before integrating\n",
        "- Use the example code in this notebook as a starting point\n",
        "- Don't forget to record your demo video!\n",
        "\n",
        "**Happy coding!** ðŸš€"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}